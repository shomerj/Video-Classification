{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators (to help understand map-reduce)\n",
    "\n",
    "A generator is an object on which you can call the method `next` such that on every call it returns a value until it raises a `StopIteration` exception, signaling that all values have been generated.  This object is called an iterator.\n",
    "\n",
    "Normal functions return a single value (or a list of values) all at once with `return`.  When `return` is called the states of all the local variables in the function are lost.  **Generators functions `yield` control back to the calling program when returning a value, but the local state of the function is maintained, so when `next` is called, the generator can start where it left off.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# an example of a function returning a generator\n",
    "def hold_client(name):\n",
    "    yield 'Hello, %s! You will be connected soon' % name\n",
    "    yield 'Dear %s, could you please wait a bit.' % name\n",
    "    yield 'Sorry %s, we will play a nice music for you!' % name\n",
    "    yield '%s, your call is extremely important to us!' % name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wait = hold_client('Frank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, Frank! You will be connected soon'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wait.next() #python 2\n",
    "next(wait) #python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But why use a generator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating list\n",
      "Type:  <class 'list'>\n",
      "Length:  1000\n",
      "Size (bytes):  9024\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "# list\n",
    "print(\"Evaluating list\")\n",
    "lst = [x for x in range(0,1000)]\n",
    "print(\"Type: \", type(lst))\n",
    "print(\"Length: \", len(lst))\n",
    "print(\"Size (bytes): \", getsizeof(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating generator\n",
      "Type:  <class 'generator'>\n",
      "Size (bytes):  88\n"
     ]
    }
   ],
   "source": [
    "# generator\n",
    "print(\"Evaluating generator\")\n",
    "gen = (x for x in range(0,1000))\n",
    "print(\"Type: \", type(gen))\n",
    "#print \"Length: \", len(gen) # causes error!\n",
    "print(\"Size (bytes): \", getsizeof(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gen.next() Python 2\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generators are memory efficient, returning results as needed.  This is useful for large datasets.  Additionally, sometimes it is useful to save the state of a function instead of starting from scratch.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classic example of the utility of generators is finding the prime numbers that exist in a range of values.  See a nice description [here.](https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadoop Map Reduce in Python\n",
    "- Technically Hadoop Map Reduce jobs need to be written in Java\n",
    "- mrjob is a Python library that makes use of _hadoop streaming_\n",
    "    - Basically, all function inputs and outputs are written to/from stdin/stdout  \n",
    "- typically run it from command line: `$ python python_mr_file.py textfile.txt` \n",
    "\n",
    "to install:\n",
    "`$ pip install mrjob`  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic structure of an mrjob file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MyMR(MRJob):\n",
    "    \n",
    "    def mapper(self, key, value):\n",
    "        pass\n",
    "    \n",
    "    def reducer(self, key, value): \n",
    "        pass\n",
    "    \n",
    "if __name__ == '__main__': \n",
    "    MyMR.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MRJob for Word Count\n",
    "--------------------------\n",
    "\n",
    "Q: Count the frequency of words using MRJob.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the `WordCount.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting WordCount.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile WordCount.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MyMR(MRJob):\n",
    "    \n",
    "    # key = _, value = line\n",
    "    def mapper(self, _, line):\n",
    "        words = line.split()\n",
    "        \n",
    "        for word in words:\n",
    "            yield (word, 1)\n",
    "    \n",
    "    # key = word, value = count\n",
    "    def reducer(self, word, count):\n",
    "        yield (word, sum(count))\n",
    "    \n",
    "if __name__ == '__main__': \n",
    "    MyMR.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run it locally on the `words.txt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /var/folders/ck/09slxnrw8xjf1_001s7djbx80000gn/T/WordCount.courtney.20171018.041814.798084\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /var/folders/ck/09slxnrw8xjf1_001s7djbx80000gn/T/WordCount.courtney.20171018.041814.798084/output...\n",
      "\"again\"\t1\n",
      "\"hello\"\t2\n",
      "\"is\"\t2\n",
      "\"line\"\t2\n",
      "\"second\"\t1\n",
      "\"the\"\t2\n",
      "\"third\"\t1\n",
      "\"this\"\t2\n",
      "\"world\"\t1\n",
      "Removing temp directory /var/folders/ck/09slxnrw8xjf1_001s7djbx80000gn/T/WordCount.courtney.20171018.041814.798084...\n"
     ]
    }
   ],
   "source": [
    "!python WordCount.py words.txt #output to stdout, ! runs from bash (stdin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /var/folders/ck/09slxnrw8xjf1_001s7djbx80000gn/T/WordCount.courtney.20171018.041826.857052\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /var/folders/ck/09slxnrw8xjf1_001s7djbx80000gn/T/WordCount.courtney.20171018.041826.857052/output...\n",
      "Removing temp directory /var/folders/ck/09slxnrw8xjf1_001s7djbx80000gn/T/WordCount.courtney.20171018.041826.857052...\n"
     ]
    }
   ],
   "source": [
    "!python WordCount.py words.txt > wordout.txt #output redirected to wordout.txt to save output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something to note - mrjob only cares that key, value pairs are parameters in the mappers, combiners, and reducers, and that key,value pairs are yielded.  They do not need to match up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing WordCount_gibberish.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile WordCount_gibberish.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MyMR(MRJob):\n",
    "    \n",
    "    # key = abba, value = rice_crispy_treats\n",
    "    def mapper(self, abba, rice_crispy_treats):\n",
    "        words = rice_crispy_treats.split()\n",
    "        \n",
    "        for word in words:\n",
    "            yield (word, 1)\n",
    "    \n",
    "    # key = SpeedRacer, value = Mach5\n",
    "    def reducer(self, SpeedRacer, Mach5):\n",
    "        yield (SpeedRacer, sum(Mach5))\n",
    "    \n",
    "if __name__ == '__main__': \n",
    "    MyMR.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\r\n",
      "Creating temp directory /var/folders/b6/2j90l3sj441b9rw4gyxzqlm80000gn/T/WordCount_gibberish.jacobshomer.20171018.172134.095308\r\n",
      "Running step 1 of 1...\r\n",
      "Streaming final output from /var/folders/b6/2j90l3sj441b9rw4gyxzqlm80000gn/T/WordCount_gibberish.jacobshomer.20171018.172134.095308/output...\r\n",
      "\"again\"\t1\r\n",
      "\"hello\"\t2\r\n",
      "\"is\"\t2\r\n",
      "\"line\"\t2\r\n",
      "\"second\"\t1\r\n",
      "\"the\"\t2\r\n",
      "\"third\"\t1\r\n",
      "\"this\"\t2\r\n",
      "\"world\"\t1\r\n",
      "Removing temp directory /var/folders/b6/2j90l3sj441b9rw4gyxzqlm80000gn/T/WordCount_gibberish.jacobshomer.20171018.172134.095308...\r\n"
     ]
    }
   ],
   "source": [
    "!python WordCount_gibberish.py words.txt #output to standard out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
